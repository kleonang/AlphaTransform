# AlphaTransform: A Quantitative Trading Strategy Generation and Backtesting Framework 

AlphaTransform is a Reinforcement Learning-based Alpha Generation and Alpha Backtesting system. 

This repository contains a formulaic alpha generator using Reinforcement Learning (with a Transformer as the policy network) in `alphagen`, as well as a backtesting system in `backtester` that tests alphas generated by the alpha generator that can be used to train and test the alpha generator.

## Architecture
Here is a high-level overview of AlphaTransform's architecture:
<img width="902" alt="AlphaTransform Architecture" src="https://github.com/kleonang/AlphaTransform/assets/35778042/661be04c-b0da-4845-9535-840994444286">

## Usage
### Config
The default parameters in `config.py` works on the input data provided in the `data` directory, but feel free to change the parameters if necessary (e.g. if using your own dataset or additional operators). 
The training of the RL agent will depend on these specified parameters. 

### Training
To train a model on the provided data in the `data` directory, run:
```bash
python3 train_maskable_ppo.py <seed> <loss_metric> <num_steps>
```
where `<seed>` is any integer serving as a random seed for reproducible output, and `<loss_metric>` is a choice of `IC`, `RIC`, or `Sharpe`.
`<num_steps>` refers to the number of steps that the RL training loop will run for, and is an optional parameter (with a default of 100,000). 

An example training command is:
```bash
python3 train_maskable_ppo.py 42 Sharpe
```

### Testing
To test a previously trained model, run:
```bash
python3 test_maskable_ppo.py <checkpoint_path> <num_distinct_alphas_to_generate> 
```
where `<checkpoint_path>` is the file path of the saved model checkpoint.
`<num_distinct_alphas_to_generate>` is the number of distinct alphas (with unique loss values) to generate in the batch, 
and is an optional parameter (with a default of 100). 

An example test command is:
```bash
python3 test_maskable_ppo.py ./checkpoints/new_Sharpe_42_20231105171143/100352_steps.zip
```

## References
The data provided in the `data` directory was computed from the Google Finance dataset provided by:
```
@article{feng2019temporal,
  title={Temporal relational ranking for stock prediction},
  author={Feng, Fuli and He, Xiangnan and Wang, Xiang and Luo, Cheng and Liu, Yiqun and Chua, Tat-Seng},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={37},
  number={2},
  pages={27},
  year={2019},
  publisher={ACM}
}
```

The design and representation of the Alpha Generator were inspired and modified from this paper:
```
@inproceedings{alphagen,
    author = {Yu, Shuo and Xue, Hongyan and Ao, Xiang and Pan, Feiyang and He, Jia and Tu, Dandan and He, Qing},
    title = {Generating Synergistic Formulaic Alpha Collections via Reinforcement Learning},
    year = {2023},
    doi = {10.1145/3580305.3599831},
    booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
}
```


